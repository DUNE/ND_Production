[global]
group      = dune
experiment = dune
wrapper = file:///${FIFE_UTILS_DIR}/libexec/fife_wrap
version = v07_06_00
quals   = e17:prof
utilversion = v07_06_00
utilquals   = %(quals)s
anaversion = %(version)s
basename  = override_me
fclfile = prodgenie_%(basename)s_dune10kt_1x2x6.fcl
anafclfile = override_me
outdir = /pnfs/dune/scratch/dunepro/dropbox/mcc11/%(basename)s
logdir = /pnfs/dune/scratch/dunepro/test_MCC11/logs/%(basename)s
tardir = /pnfs/dune/resilient/users/dunepro
out_ana_dir = override_me
#tarfile = override_me
datastream = override_me
pandoradir= /pnfs/dune/scratch/dunepro/dropbox/PDSPProd2/PandoraFiles
campaign = PDSPProd4
tarname = override_me
nevents = -1
runtime_dir = override_me
cuda_dir = override_me
ARCUBE_INDEX = ${PROCESS}

[env_pass]
#IFDH_DEBUG = 1
SAM_EXPERIMENT=%(experiment)s
SAM_GROUP=%(group)s
SAM_STATION=%(experiment)s
IFDH_CP_MAXRETRIES=2
XRD_CONNECTIONRETRY=32
XRD_REQUESTTIMEOUT=14400
XRD_REDIRECTLIMIT=255
XRD_LOADBALANCERTTL=7200
XRD_STREAMTIMEOUT=14400
UPS_OVERRIDE="-H Linux64bit+3.10-2.17"

ARCUBE_OUTDIR_BASE = '/pscratch/sd/d/dunepro/output/2x2_poms_test'
ARCUBE_LOGDIR_BASE = '/pscratch/sd/d/dunepro/logs/2x2_poms_test'

[submit]
G          = %(group)s
subgroup   = prod_mcsim
N          = 1
#maxConcurrent	       = 400
#N          = 10
resource-provides      = usage_model=OPPORTUNISTIC,DEDICATED,OFFSITE
cpu                    = 1
expected-lifetime      = 5h
#timeout		       = None
disk                  = 20GB
memory                 = 2500MB
#memory                 = 4000MB
#OS = SL7
email-to               = mkramer@lbl.gov

#If we need tar files
#append_condor_requirements = \(\(TARGET.has_avx==true\)\&\&\(\(\(TARGET.HAS_CVMFS_dune_opensciencegrid_org==true\)\&\&\(TARGET.CVMFS_dune_opensciencegrid_org_REVISION\>=883\)\&\&\(TARGET.HAS_cvmfs_fifeuser1_opensciencegrid_org==true\&\&TARGET.HAS_cvmfs_fifeuser2_opensciencegrid_org==true\&\&TARGET.HAS_cvmfs_fifeuser3_opensciencegrid_org==true\&\&TARGET.HAS_cvmfs_fifeuser4_opensciencegrid_org==true\)\)\|\|\(TARGET.GLIDEIN_Site==\\\"T3_US_NERSC\\\"\)\|\|\(TARGET.GLIDEIN_Site==\\\"Florida\\\"\)\)\)

# we do not need tar files
append_condor_requirements = \(\(TARGET.has_avx==true\)\&\&\(\(\(TARGET.HAS_CVMFS_dune_opensciencegrid_org==true\)\&\&\(TARGET.CVMFS_fermilab_opensciencegrid_org_REVISION\>=9822\)\&\&\(TARGET.CVMFS_dune_opensciencegrid_org_REVISION\>=1015\)\&\&\(TARGET.HAS_SINGULARITY==true\)\)\|\|\(stringListIMember\(TARGET.GLIDEIN_Site,\\\"Florida,NERSC-Perlmutter-CPU,NERSC-Perlmutter-GPU,NERSC-Perlmutter-TRITON\\\",\\\",\\\"\)\)\)\)
lines_1    = +SingularityImage=\\\"/cvmfs/singularity.opensciencegrid.org/fermilab/fnal-wn-sl7:latest\\\"
lines_2    = +FERMIHTC_AutoRelease=True
lines_3    = +FERMIHTC_GraceMemory=2000
lines_4    = +FERMIHTC_GraceLifetime=86400
mail_never                 = True
#site       = CERN,FermiGrid,FNAL,Caltech,London,Sheffield,Nebraska,Omaha,BU,Michigan,BNL,UCSD,Liverpool,Manchester,Lancaster,SGridOxford,RAL,Florida,SGridECDF,CCIN2P3,FZU,Colorado
# smaller than usual site list because we ask for 3500MB and 35 run time by default
site       = BNL,BR_CBPF,Bristol,CA_Victoria,CCIN2P3,CERN,Clemson,Colorado,FermiGrid,Florida,FZU,JINR_CLOUD,Lancaster,Liverpool,London,London_QMUL,Manchester,NotreDame,Omaha,PIC,RAL,SGrid,SGridECDF,SGridOxford,Sheffield,SURFsara,UCSD,Wisconsin
#f_0 = %(tardir)s/%(tarfile)s

[job_setup]
#debug       = True
find_setups = True
source_1    = /cvmfs/dune.opensciencegrid.org/products/dune/setup_dune.sh
#setup_1     = ifdhc
#setup_2     = protoduneana %(anaversion)s -q %(quals)s
#setup_3     = duneutil %(utilversion)s -q %(utilquals)s
#setup_4     = dune_oslibs v1_0_0
multifile   = False
prescript_1 = ln -s %(runtime_dir)s/* .
#postscript_1 = extractor_prod.py --infile $(ls *reco1_${CLUSTER}_${PROCESS}_${FILETIMESTAMP}.root) --appfamily art --appname reco --appversion %(version)s --campaign %(campaign)s --no_crc --data_stream %(datastream)s > $(ls *_reco1_${CLUSTER}_${PROCESS}_${FILETIMESTAMP}.root).json 
#postscript_7 = pandora_metadata.py --infile $(ls *_Pandora_Events.pndr)  --appfamily art --appname reco --appversion %(version)s --campaign %(campaign)s --no_crc --data_stream %(datastream)s --input_json $(ls *_reco1_${CLUSTER}_${PROCESS}_${FILETIMESTAMP}.root.json) > $(ls *_Pandora_Events.pndr).json
export_1     = FILETIMESTAMP=$(date -u +%%Y%%m%%dT%%H%%M%%SZ)
export_2     = ARCUBE_INDEX=%(ARCUBE_INDEX)s
ifdh_art     = False

[sam_consumer]
limit       = 1
appvers	    = %(version)s
schema      = root
appname     = reco
appfamily   = art

[executable]
name      = %(runtime_dir)s/run_edep_sim.sh
#arg_1     = -c

[job_output]
addoutput = *randomstuff*.root
#rename      = unique
dest          = %(outdir)s
declare_metadata = True
metadata_extractor = json
add_location = False
launch_dest_check = False

[stage_genie]
env_pass.ARCUBE_OUT_NAME = '2x2_poms_test.genie.rock'
env_pass.ARCUBE_RUNTIME = 'NONE'
env_pass.ARCUBE_DET_LOCATION = 'MiniRun5-Rock'
env_pass.ARCUBE_DK2NU_DIR = '/dvs_ro/cfs/cdirs/dune/users/mkramer/2x2EventGeneration/NuMI_dk2nu/newtarget-200kA_20220409'
env_pass.ARCUBE_EXPOSURE = '1E15'
env_pass.ARCUBE_GEOM = 'geometry/Merged2x2MINERvA_v4/Merged2x2MINERvA_v4_justRock.gdml'
env_pass.ARCUBE_TUNE = 'AR23_20i_00_000'
env_pass.ARCUBE_RUN_OFFSET = '1000000000'
env_pass.ARCUBE_XSEC_FILE = '/dvs_ro/cfs/cdirs/dune/users/mkramer/2x2EventGeneration/inputs/NuMI/genie_xsec-3.04.00-noarch-AR2320i00000-k250-e1000/v3_04_00/NULL/AR2320i00000-k250-e1000/data/gxspl-NUsmall.xml'
job_setup.prescript_1 = printf "cd %(runtime_dir)s\n./run_genie.sh\n" > genie_wrapper.sh
job_setup.prescript_2 = chmod u+x genie_wrapper.sh
executable.name = ./genie_wrapper.sh

